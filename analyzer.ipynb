{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers for spanish nlp\n",
    "import spacy\n",
    "nlp_es = spacy.load('es_core_news_sm')\n",
    "\n",
    "def normalizeTokens_es(word_list, extra_stop=[], lemma = True):\n",
    "    #We can use a generator here as we just need to iterate over it\n",
    "    normalized = []\n",
    "    if type(word_list) == list and len(word_list) == 1:\n",
    "        word_list = word_list[0]\n",
    "\n",
    "    if type(word_list) == list:\n",
    "        word_list = ' '.join([str(elem) for elem in word_list]) \n",
    "\n",
    "    doc = nlp_es(word_list.lower(), disable=['parser', 'ner'])\n",
    "    \n",
    "    # add the property of stop word to words considered as stop words\n",
    "    if len(extra_stop) > 0:\n",
    "        for stopword in extra_stop:\n",
    "            lexeme = nlp_es.vocab[stopword]\n",
    "            lexeme.is_stop = True\n",
    "\n",
    "    if lemma:\n",
    "        for w in doc:\n",
    "            # if it's not a stop word or punctuation mark, add it to our article\n",
    "            if w.text != '\\n' and not w.is_stop and not w.is_punct and not w.like_num and len(w.text.strip()) > 0:\n",
    "            # we add the lematized version of the word\n",
    "                normalized.append(str(w.lemma_))\n",
    "    else:\n",
    "        for w in doc:\n",
    "            # if it's not a stop word or punctuation mark, add it to our article\n",
    "            if w.text != '\\n' and not w.is_stop and not w.is_punct and not w.like_num and len(w.text.strip()) > 0:\n",
    "            # we add the lematized version of the word\n",
    "                normalized.append(str(w.text.strip()))\n",
    "\n",
    "    return normalized\n",
    "\n",
    "def word_tokenize_es(word_list):\n",
    "    tokenized = []\n",
    "    # pass word list through language model.\n",
    "    doc = nlp_es(word_list)\n",
    "    for token in doc:\n",
    "        if not token.is_punct and len(token.text.strip()) > 0:\n",
    "            tokenized.append(token.text)\n",
    "    return tokenized\n",
    "\n",
    "def sent_tokenize_es(word_list, model=nlp_es):\n",
    "    doc = model(word_list)\n",
    "    sentences = [sent.text.strip() for sent in doc.sents]\n",
    "    return sentences\n",
    "\n",
    "def normalize(vector):\n",
    "    normalized_vector = vector / np.linalg.norm(vector)\n",
    "    return normalized_vector\n",
    "\n",
    "def dimension(model, positives, negatives):\n",
    "    diff = sum([normalize(model[x]) for x in positives]) - sum([normalize(model[y]) for y in negatives])\n",
    "    return diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_sents</th>\n",
       "      <th>normalized_sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gaceta_1421.txt</td>\n",
       "      <td>Vamos a darle la palabra a nuestra querida Vic...</td>\n",
       "      <td>[[Vamos, a, darle, la, palabra, a, nuestra, qu...</td>\n",
       "      <td>[[darle, palabra, querida, vicepresidenta, olg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gaceta_144.txt</td>\n",
       "      <td>La Presidencia ofrece el uso de la palabra al ...</td>\n",
       "      <td>[[La, Presidencia, ofrece, el, uso, de, la, pa...</td>\n",
       "      <td>[[presidencia, ofrece, palabra, doctor, enriqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gaceta_37.txt</td>\n",
       "      <td>Tiene el uso de la palabra el Senador Iván Cep...</td>\n",
       "      <td>[[Tiene, el, uso, de, la, palabra, el, Senador...</td>\n",
       "      <td>[[palabra, senador, iván, cepeda], [interviene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gaceta_38.txt</td>\n",
       "      <td>El Presidente, Honorable Senador Jhon Harold S...</td>\n",
       "      <td>[[El, Presidente, Honorable, Senador, Jhon, Ha...</td>\n",
       "      <td>[[presidente, honorable, senador, jhon, harold...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gaceta_43.txt</td>\n",
       "      <td>La Presidencia concede el uso de la palabra a ...</td>\n",
       "      <td>[[La, Presidencia, concede, el, uso, de, la, p...</td>\n",
       "      <td>[[presidencia, concede, palabra, honorables, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gaceta_44.txt</td>\n",
       "      <td>La Presidencia concede el uso de la palabra al...</td>\n",
       "      <td>[[La, Presidencia, concede, el, uso, de, la, p...</td>\n",
       "      <td>[[presidencia, concede, palabra, honorable, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gaceta_46.txt</td>\n",
       "      <td>Atendiendo instrucciones de la Presidencia, la...</td>\n",
       "      <td>[[Atendiendo, instrucciones, de, la, Presidenc...</td>\n",
       "      <td>[[atendiendo, instrucciones, presidencia, secr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gaceta_47.txt</td>\n",
       "      <td>La Presidencia concede el uso de la palabra al...</td>\n",
       "      <td>[[La, Presidencia, concede, el, uso, de, la, p...</td>\n",
       "      <td>[[presidencia, concede, palabra, citante, hono...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gaceta_47_2020.txt</td>\n",
       "      <td>Bueno, se abre la discusión del Orden del Día,...</td>\n",
       "      <td>[[Bueno, se, abre, la, discusión, del, Orden, ...</td>\n",
       "      <td>[[abre, discusión, orden, cierra, discusión, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gaceta_48.txt</td>\n",
       "      <td>En ese orden de ideas, cedemos el uso de la pa...</td>\n",
       "      <td>[[En, ese, orden, de, ideas, cedemos, el, uso,...</td>\n",
       "      <td>[[orden, ideas, cedemos, palabra, senadores, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gaceta_49.txt</td>\n",
       "      <td>Me pide la palabra la Senadora Victoria Sandin...</td>\n",
       "      <td>[[Me, pide, la, palabra, la, Senadora, Victori...</td>\n",
       "      <td>[[pide, palabra, senadora, victoria, sandino, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name                                               text  \\\n",
       "0      gaceta_1421.txt  Vamos a darle la palabra a nuestra querida Vic...   \n",
       "1       gaceta_144.txt  La Presidencia ofrece el uso de la palabra al ...   \n",
       "2        gaceta_37.txt  Tiene el uso de la palabra el Senador Iván Cep...   \n",
       "3        gaceta_38.txt  El Presidente, Honorable Senador Jhon Harold S...   \n",
       "4        gaceta_43.txt  La Presidencia concede el uso de la palabra a ...   \n",
       "5        gaceta_44.txt  La Presidencia concede el uso de la palabra al...   \n",
       "6        gaceta_46.txt  Atendiendo instrucciones de la Presidencia, la...   \n",
       "7        gaceta_47.txt  La Presidencia concede el uso de la palabra al...   \n",
       "8   gaceta_47_2020.txt  Bueno, se abre la discusión del Orden del Día,...   \n",
       "9        gaceta_48.txt  En ese orden de ideas, cedemos el uso de la pa...   \n",
       "10       gaceta_49.txt  Me pide la palabra la Senadora Victoria Sandin...   \n",
       "\n",
       "                                      tokenized_sents  \\\n",
       "0   [[Vamos, a, darle, la, palabra, a, nuestra, qu...   \n",
       "1   [[La, Presidencia, ofrece, el, uso, de, la, pa...   \n",
       "2   [[Tiene, el, uso, de, la, palabra, el, Senador...   \n",
       "3   [[El, Presidente, Honorable, Senador, Jhon, Ha...   \n",
       "4   [[La, Presidencia, concede, el, uso, de, la, p...   \n",
       "5   [[La, Presidencia, concede, el, uso, de, la, p...   \n",
       "6   [[Atendiendo, instrucciones, de, la, Presidenc...   \n",
       "7   [[La, Presidencia, concede, el, uso, de, la, p...   \n",
       "8   [[Bueno, se, abre, la, discusión, del, Orden, ...   \n",
       "9   [[En, ese, orden, de, ideas, cedemos, el, uso,...   \n",
       "10  [[Me, pide, la, palabra, la, Senadora, Victori...   \n",
       "\n",
       "                                     normalized_sents  \n",
       "0   [[darle, palabra, querida, vicepresidenta, olg...  \n",
       "1   [[presidencia, ofrece, palabra, doctor, enriqu...  \n",
       "2   [[palabra, senador, iván, cepeda], [interviene...  \n",
       "3   [[presidente, honorable, senador, jhon, harold...  \n",
       "4   [[presidencia, concede, palabra, honorables, c...  \n",
       "5   [[presidencia, concede, palabra, honorable, se...  \n",
       "6   [[atendiendo, instrucciones, presidencia, secr...  \n",
       "7   [[presidencia, concede, palabra, citante, hono...  \n",
       "8   [[abre, discusión, orden, cierra, discusión, o...  \n",
       "9   [[orden, ideas, cedemos, palabra, senadores, c...  \n",
       "10  [[pide, palabra, senadora, victoria, sandino, ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize corpus df\n",
    "\n",
    "#get the text from the corpus\n",
    "\n",
    "import os \n",
    "import pandas\n",
    "from tqdm import tqdm\n",
    "\n",
    "senateDict = {'name' : [], 'text' : []}\n",
    "for file in os.listdir(r\"C:\\Users\\asarr\\Documents\\MACSS\\Winter 2024\\Computational Content Analysis\\corpus\\Actas comisiones del senado 2023\\clean documents\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        senateDict['name'].append(file)\n",
    "        with open(os.path.join(r\"C:\\Users\\asarr\\Documents\\MACSS\\Winter 2024\\Computational Content Analysis\\corpus\\Actas comisiones del senado 2023\\clean documents\", file), 'r', encoding = 'utf8') as f:\n",
    "            senateDict['text'].append(f.read())\n",
    "\n",
    "\n",
    "senateDF = pandas.DataFrame(senateDict)\n",
    "#senateDF['tokenized_text'] = senateDF['text'].apply(lambda x: word_tokenize_es(x))\n",
    "#senateDF['normalized_tokens'] = senateDF['tokenized_text'].apply(lambda x: normalizeTokens_es(x, extra_stop=[]))\n",
    "senateDF['tokenized_sents'] = senateDF['text'].apply(lambda x: [word_tokenize_es(s) for s in sent_tokenize_es(x)])\n",
    "senateDF['normalized_sents'] = senateDF['tokenized_sents'].apply(lambda x: [normalizeTokens_es(s, lemma=False) for s in x])\n",
    "\n",
    "senateDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#senators dataset\n",
    "\n",
    "#get names using chatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create word2vec model\n",
    "import gensim\n",
    "import numpy as np\n",
    "\n",
    "senateW2V_CBOW = gensim.models.word2vec.Word2Vec(senateDF['normalized_sents'].sum(), sg=0)\n",
    "\n",
    "#create dimensions\n",
    "Gender = dimension(senateW2V_CBOW.wv, ['mujeres', 'mujer'], ['hombres', 'hombre'])\n",
    "Age = dimension(senateW2V_CBOW.wv, ['joven', 'jóvenes', 'niños', 'niñas'], ['mayores', 'adulto', 'adultos'])\n",
    "Conflict = dimension(senateW2V_CBOW.wv, ['paz'], ['conflicto', 'violencia'])\n",
    "\n",
    "#create projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add emotionality feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
