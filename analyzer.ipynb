{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp_es = spacy.load('es_core_news_sm')\n",
    "\n",
    "def normalizeTokens_es(word_list, extra_stop=[], lemma = True):\n",
    "    #We can use a generator here as we just need to iterate over it\n",
    "    normalized = []\n",
    "    if type(word_list) == list and len(word_list) == 1:\n",
    "        word_list = word_list[0]\n",
    "\n",
    "    if type(word_list) == list:\n",
    "        word_list = ' '.join([str(elem) for elem in word_list]) \n",
    "\n",
    "    doc = nlp_es(word_list.lower(), disable=['parser', 'ner'])\n",
    "    \n",
    "    # add the property of stop word to words considered as stop words\n",
    "    if len(extra_stop) > 0:\n",
    "        for stopword in extra_stop:\n",
    "            lexeme = nlp_es.vocab[stopword]\n",
    "            lexeme.is_stop = True\n",
    "\n",
    "    if lemma:\n",
    "        for w in doc:\n",
    "            # if it's not a stop word or punctuation mark, add it to our article\n",
    "            if w.text != '\\n' and not w.is_stop and not w.is_punct and not w.like_num and len(w.text.strip()) > 0:\n",
    "            # we add the lematized version of the word\n",
    "                normalized.append(str(w.lemma_))\n",
    "    else:\n",
    "        for w in doc:\n",
    "            # if it's not a stop word or punctuation mark, add it to our article\n",
    "            if w.text != '\\n' and not w.is_stop and not w.is_punct and not w.like_num and len(w.text.strip()) > 0:\n",
    "            # we add the lematized version of the word\n",
    "                normalized.append(str(w.text.strip()))\n",
    "\n",
    "    return normalized\n",
    "\n",
    "def word_tokenize_es(word_list):\n",
    "    tokenized = []\n",
    "    # pass word list through language model.\n",
    "    doc = nlp_es(word_list)\n",
    "    for token in doc:\n",
    "        if not token.is_punct and len(token.text.strip()) > 0:\n",
    "            tokenized.append(token.text)\n",
    "    return tokenized\n",
    "\n",
    "def sent_tokenize_es(word_list, model=nlp_es):\n",
    "    doc = model(word_list)\n",
    "    sentences = [sent.text.strip() for sent in doc.sents]\n",
    "    return sentences\n",
    "\n",
    "def senator_centroid(senator):\n",
    "    senator = senator.lower().split(' ')\n",
    "    return np.average([senateW2V_CBOW.wv[x] for x in senator if x in vocab], axis=0)\n",
    "\n",
    "def cosine_similarity_adapter(x, y):\n",
    "    return cosine_similarity(x.reshape(1, -1), y.reshape(1, -1))\n",
    "\n",
    "#no uso por ahora\n",
    "\n",
    "def normalize(vector):\n",
    "    normalized_vector = vector / np.linalg.norm(vector)\n",
    "    return normalized_vector\n",
    "\n",
    "def dimension(model, positives, negatives):\n",
    "    diff = sum([normalize(model[x]) for x in positives]) - sum([normalize(model[y]) for y in negatives])\n",
    "    return diff\n",
    "\n",
    "def get_names(text):\n",
    "    messages = [{\"role\": \"system\", \"content\": \"Eres un experto en linguistica y comunicación política en el sistema político colombiano\"},\n",
    "          {\"role\": \"user\", \"content\": f\"Estos es el texto de las ultimas sesiones del congreso: {text}.Detecta los nombres propios completos (nombre y apellidos) que están en el texto. Por ejemplo, si el texto es 'El presidente Iván Duque Márquez se reunió con el ministro de salud Fernando Ruiz Gómez', el resultado esperado es 'Iván Duque Márquez, Fernando Ruiz Gómez'. Responde solo con la lista de los nombres. No des contexto adicional.\"}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4\", messages=messages)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def spacy_pos_es(word_list):\n",
    "    tags = []\n",
    "    doc = nlp_es(word_list.lower())\n",
    "    for w in doc:\n",
    "        tags.append((w.text, w.pos_, w.tag_))\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "### congress sessions corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize corpus df\n",
    "\n",
    "#get the text from the corpus\n",
    "\n",
    "import os \n",
    "import pandas\n",
    "from tqdm import tqdm\n",
    "\n",
    "senateDict = {'name' : [], 'text' : []}\n",
    "for file in os.listdir(r\"C:\\Users\\asarr\\Documents\\MACSS\\Winter 2024\\Computational Content Analysis\\corpus\\Actas comisiones del senado 2023\\clean documents\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        senateDict['name'].append(file)\n",
    "        with open(os.path.join(r\"C:\\Users\\asarr\\Documents\\MACSS\\Winter 2024\\Computational Content Analysis\\corpus\\Actas comisiones del senado 2023\\clean documents\", file), 'r', encoding = 'utf8') as f:\n",
    "            senateDict['text'].append(f.read())\n",
    "\n",
    "\n",
    "senateDF = pandas.DataFrame(senateDict)\n",
    "senateDF['tokenized_text'] = senateDF['text'].apply(lambda x: word_tokenize_es(x))\n",
    "senateDF['normalized_tokens'] = senateDF['tokenized_text'].apply(lambda x: normalizeTokens_es(x, extra_stop=[]))\n",
    "senateDF['tokenized_sents'] = senateDF['text'].apply(lambda x: [word_tokenize_es(s) for s in sent_tokenize_es(x)])\n",
    "senateDF['normalized_sents'] = senateDF['tokenized_sents'].apply(lambda x: [normalizeTokens_es(s, lemma=False) for s in x])\n",
    "senateDF['normalized_tokens_POS'] = [spacy_pos_es(t) for t in senateDF['text']]\n",
    "senateDF['proper_nouns'] = senateDF['normalized_tokens_POS'].apply(lambda x: [t[0] for t in x if t[1] == 'PROPN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congress members database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "\n",
    "request = requests.get('https://www.senado.gov.co/index.php/el-senado/senadores?lastletter=Todos#modazdirectory')\n",
    "soup = bs4.BeautifulSoup(request.text, 'html.parser')\n",
    "senators = soup.find_all('div', class_= \"modazdirectory__result modazdirectory__layout-misc_off\")\n",
    "\n",
    "senators_dict = {'senator':[], 'party':[]}\n",
    "for senator in senators:\n",
    "    senators_dict['senator'].append(senator.h3.text)\n",
    "    senators_dict['party'].append(senator.find('p').text)\n",
    "\n",
    "\n",
    "senatorsDF = pandas.DataFrame(senators_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>senator</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agudelo García Ana Paola</td>\n",
       "      <td>MIRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amín Saleme Fabio Raúl</td>\n",
       "      <td>Partido Liberal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arias Castillo Wilson Neber</td>\n",
       "      <td>Polo Democrático Alternativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asprilla Reyes Inti Raúl</td>\n",
       "      <td>Alianza Verde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Avella Esquivel Aída Yolanda</td>\n",
       "      <td>Unión Patriótica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Valencia Laserna Paloma Susana</td>\n",
       "      <td>Centro Democrático</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Vega Pérez Alejandro Alberto</td>\n",
       "      <td>Partido Liberal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Virgüez Piraquive Manuel Antonio</td>\n",
       "      <td>MIRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Zabaraín Guevara Antonio Luis</td>\n",
       "      <td>Cambio Radical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Zuleta López Isabel Cristina</td>\n",
       "      <td>Coalición Pacto Histórico - Colombia Humana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               senator  \\\n",
       "0             Agudelo García Ana Paola   \n",
       "1               Amín Saleme Fabio Raúl   \n",
       "2          Arias Castillo Wilson Neber   \n",
       "3             Asprilla Reyes Inti Raúl   \n",
       "4         Avella Esquivel Aída Yolanda   \n",
       "..                                 ...   \n",
       "100     Valencia Laserna Paloma Susana   \n",
       "101       Vega Pérez Alejandro Alberto   \n",
       "102  Virgüez Piraquive Manuel Antonio    \n",
       "103      Zabaraín Guevara Antonio Luis   \n",
       "104      Zuleta López Isabel Cristina    \n",
       "\n",
       "                                           party  \n",
       "0                                           MIRA  \n",
       "1                                Partido Liberal  \n",
       "2                   Polo Democrático Alternativo  \n",
       "3                                  Alianza Verde  \n",
       "4                             Unión Patriótica    \n",
       "..                                           ...  \n",
       "100                           Centro Democrático  \n",
       "101                              Partido Liberal  \n",
       "102                                         MIRA  \n",
       "103                               Cambio Radical  \n",
       "104  Coalición Pacto Histórico - Colombia Humana  \n",
       "\n",
       "[105 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add remaining demographic information(opposition/government/independent, gender, ethnic identity)\n",
    "senatorsDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load SEL\n",
    "import pandas\n",
    "sel_path = r'C:\\Users\\asarr\\Documents\\MACSS\\Winter 2024\\Computational Content Analysis\\colombian-congress-nlp\\Spanish emotional lexicon\\SEL.txt'\n",
    "sel = pandas.read_csv(sel_path, sep=\"\\t\", names=[\"word\", \"probability\", \"category\"], encoding = 'ISO-8859-1')\n",
    "sel = sel.drop(0)\n",
    "\n",
    "#create df with only words with probability > 0.5\n",
    "sel['probability'] = sel['probability'].astype(float)\n",
    "#sel = sel[sel['probability'] > 0.3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Alegría', 'Enojo', 'Miedo', 'Repulsión', 'Sorpresa', 'Tristeza'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#iterate over rows and add words to the dictionary according to their category\n",
    "positives_lst = {}\n",
    "for index, row in sel.iterrows():\n",
    "    if row['category'] not in positives_lst:\n",
    "        positives_lst[row['category']] = []\n",
    "    positives_lst[row['category']].append(row['word'])\n",
    "\n",
    "positives_lst.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create word2vec model\n",
    "import gensim\n",
    "import numpy as np\n",
    "\n",
    "senateW2V_CBOW = gensim.models.word2vec.Word2Vec(senateDF['normalized_sents'].sum(), sg=0)\n",
    "vocab = list(senateW2V_CBOW.wv.key_to_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove words in positives_lst that are not in the vocabulary\n",
    "positives_lst_vocab = {'Alegría': [], 'Enojo': [], 'Repulsión': [], 'Sorpresa': [], 'Tristeza': [], 'Miedo': []}\n",
    "\n",
    "#create positives\n",
    "for emotion in positives_lst.keys():\n",
    "    for word in positives_lst[emotion]:\n",
    "        if word in vocab:\n",
    "            positives_lst_vocab[emotion].append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate centroid for each emotion\n",
    "centroids = {'Alegría': [], 'Enojo': [], 'Repulsión': [], 'Sorpresa': [], 'Tristeza': [], 'Miedo': []}\n",
    "\n",
    "for emotion in centroids.keys():\n",
    "    centroids[emotion] = np.average([senateW2V_CBOW.wv[x] for x in positives_lst_vocab[emotion]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(centroids['Alegría'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7035392]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate vector for each senator\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#senatorsDF['centroid'][0].shape\n",
    "\n",
    "\n",
    "cosine_similarity_adapter(senatorsDF['centroid'][0], centroids['Alegría'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asarr\\AppData\\Local\\Temp\\ipykernel_6008\\2212388748.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  senatorsDF['centroid'] = senatorsDF['senator'].apply(senator_centroid)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>senator</th>\n",
       "      <th>party</th>\n",
       "      <th>centroid</th>\n",
       "      <th>happiness_cs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agudelo García Ana Paola</td>\n",
       "      <td>MIRA</td>\n",
       "      <td>[0.29471964, 0.37753928, 0.2426602, -0.2494265...</td>\n",
       "      <td>[[0.7035392]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amín Saleme Fabio Raúl</td>\n",
       "      <td>Partido Liberal</td>\n",
       "      <td>[0.20876464, 0.38049096, 0.252151, -0.1242769,...</td>\n",
       "      <td>[[0.7596903]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arias Castillo Wilson Neber</td>\n",
       "      <td>Polo Democrático Alternativo</td>\n",
       "      <td>[0.64010555, 0.9771447, 0.46279737, -0.8212334...</td>\n",
       "      <td>[[0.66354245]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asprilla Reyes Inti Raúl</td>\n",
       "      <td>Alianza Verde</td>\n",
       "      <td>[0.1643892, 0.27331486, 0.11713018, -0.1171381...</td>\n",
       "      <td>[[0.81215334]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Avella Esquivel Aída Yolanda</td>\n",
       "      <td>Unión Patriótica</td>\n",
       "      <td>[0.05746005, 0.11026829, -0.029397137, -0.0371...</td>\n",
       "      <td>[[0.98015785]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Valencia Laserna Paloma Susana</td>\n",
       "      <td>Centro Democrático</td>\n",
       "      <td>[0.25965682, 0.3489499, 0.26302227, -0.2273508...</td>\n",
       "      <td>[[0.7063205]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Vega Pérez Alejandro Alberto</td>\n",
       "      <td>Partido Liberal</td>\n",
       "      <td>[0.3635928, 0.46250454, 0.30063865, -0.2192173...</td>\n",
       "      <td>[[0.7205496]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Virgüez Piraquive Manuel Antonio</td>\n",
       "      <td>MIRA</td>\n",
       "      <td>[0.28032327, 0.36318165, 0.1143739, -0.3107822...</td>\n",
       "      <td>[[0.7319552]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Zabaraín Guevara Antonio Luis</td>\n",
       "      <td>Cambio Radical</td>\n",
       "      <td>[0.3004256, 0.2685386, 0.25686726, -0.29404494...</td>\n",
       "      <td>[[0.66624224]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Zuleta López Isabel Cristina</td>\n",
       "      <td>Coalición Pacto Histórico - Colombia Humana</td>\n",
       "      <td>[0.18210036, 0.28030643, 0.10969005, -0.204490...</td>\n",
       "      <td>[[0.80451506]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               senator  \\\n",
       "0             Agudelo García Ana Paola   \n",
       "1               Amín Saleme Fabio Raúl   \n",
       "2          Arias Castillo Wilson Neber   \n",
       "3             Asprilla Reyes Inti Raúl   \n",
       "4         Avella Esquivel Aída Yolanda   \n",
       "..                                 ...   \n",
       "100     Valencia Laserna Paloma Susana   \n",
       "101       Vega Pérez Alejandro Alberto   \n",
       "102  Virgüez Piraquive Manuel Antonio    \n",
       "103      Zabaraín Guevara Antonio Luis   \n",
       "104      Zuleta López Isabel Cristina    \n",
       "\n",
       "                                           party  \\\n",
       "0                                           MIRA   \n",
       "1                                Partido Liberal   \n",
       "2                   Polo Democrático Alternativo   \n",
       "3                                  Alianza Verde   \n",
       "4                             Unión Patriótica     \n",
       "..                                           ...   \n",
       "100                           Centro Democrático   \n",
       "101                              Partido Liberal   \n",
       "102                                         MIRA   \n",
       "103                               Cambio Radical   \n",
       "104  Coalición Pacto Histórico - Colombia Humana   \n",
       "\n",
       "                                              centroid    happiness_cs  \n",
       "0    [0.29471964, 0.37753928, 0.2426602, -0.2494265...   [[0.7035392]]  \n",
       "1    [0.20876464, 0.38049096, 0.252151, -0.1242769,...   [[0.7596903]]  \n",
       "2    [0.64010555, 0.9771447, 0.46279737, -0.8212334...  [[0.66354245]]  \n",
       "3    [0.1643892, 0.27331486, 0.11713018, -0.1171381...  [[0.81215334]]  \n",
       "4    [0.05746005, 0.11026829, -0.029397137, -0.0371...  [[0.98015785]]  \n",
       "..                                                 ...             ...  \n",
       "100  [0.25965682, 0.3489499, 0.26302227, -0.2273508...   [[0.7063205]]  \n",
       "101  [0.3635928, 0.46250454, 0.30063865, -0.2192173...   [[0.7205496]]  \n",
       "102  [0.28032327, 0.36318165, 0.1143739, -0.3107822...   [[0.7319552]]  \n",
       "103  [0.3004256, 0.2685386, 0.25686726, -0.29404494...  [[0.66624224]]  \n",
       "104  [0.18210036, 0.28030643, 0.10969005, -0.204490...  [[0.80451506]]  \n",
       "\n",
       "[99 rows x 4 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senatorsDF['centroid'] = senatorsDF['senator'].apply(senator_centroid)\n",
    "senatorsDF = senatorsDF.dropna()\n",
    "senatorsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate cosine similarity between each senator and each emotion\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "senatorsDF['happiness_cs'] = senatorsDF['centroid'].apply(lambda x: cosine_similarity_adapter(x, centroids['Alegría']))\n",
    "senatorsDF['anger_cs'] = senatorsDF['centroid'].apply(lambda x: cosine_similarity_adapter(x, centroids['Enojo']))\n",
    "senatorsDF['disgust_cs'] = senatorsDF['centroid'].apply(lambda x: cosine_similarity_adapter(x, centroids['Repulsión']))\n",
    "senatorsDF['surprise_cs'] = senatorsDF['centroid'].apply(lambda x: cosine_similarity_adapter(x, centroids['Sorpresa']))\n",
    "senatorsDF['sadness_cs'] = senatorsDF['centroid'].apply(lambda x: cosine_similarity_adapter(x, centroids['Tristeza']))\n",
    "senatorsDF['fear_cs'] = senatorsDF['centroid'].apply(lambda x: cosine_similarity_adapter(x, centroids['Miedo']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['senator', 'party', 'centroid', 'happiness_cs', 'anger_cs',\n",
       "       'disgust_cs', 'surprise_cs', 'sadness_cs', 'fear_cs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senatorsDF.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
